{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\nimport xgboost, numpy, textblob, string, pickle\nfrom nltk.corpus import stopwords","execution_count":48,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load Data\ndata = pd.read_csv(\"../input/textclassification/sample.csv\",names=['desc', 'label'], header=None)\ndata.head()","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"                                                desc       label\n0  Depreciation of tangible fixed assets - owned ...     d_and_a\n1        Cost of equity settled share based payments  adjustment\n2                           Amortisation of software     d_and_a\n3                      Auditor's remuneration: Audit       other\n4               Operating lease payables - equipment       other","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>desc</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Depreciation of tangible fixed assets - owned ...</td>\n      <td>d_and_a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cost of equity settled share based payments</td>\n      <td>adjustment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Amortisation of software</td>\n      <td>d_and_a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Auditor's remuneration: Audit</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Operating lease payables - equipment</td>\n      <td>other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean Text\ndef cleanText(text):\n    # Remove unwanted /r, /n, spaces and quotes\n    textParsed = text.replace(\"\\r\", \" \")\n    textParsed = textParsed.replace(\"\\n\", \" \")\n    textParsed = textParsed.replace(\"    \", \" \")\n    textParsed = textParsed.replace('\"\"', '')\n\n    # Convert text to lower case\n    textParsed = textParsed.lower()\n\n    # Remove punctuations\n    punctuation_signs = list(\"?:!.,);-/(\")\n    for punct_sign in punctuation_signs:\n        textParsed = textParsed.replace(punct_sign, '')\n\n    # Remove's\n    textParsed = textParsed.replace(\"'s\", \"\")\n    \n    # Remove stopwords\n    stop_words = stopwords.words('english')\n    for stop_word in stop_words:\n        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n        textParsed = textParsed.replace(regex_stopword, '')\n    return textParsed","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"descParsed = []\nfor text in data['desc']:\n    textparsed = cleanText(text)\n    descParsed.append(textparsed)\ndata['desc_parsed'] = descParsed\ndata.head()","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"                                                desc       label  \\\n0  Depreciation of tangible fixed assets - owned ...     d_and_a   \n1        Cost of equity settled share based payments  adjustment   \n2                           Amortisation of software     d_and_a   \n3                      Auditor's remuneration: Audit       other   \n4               Operating lease payables - equipment       other   \n\n                                         desc_parsed  \n0  depreciation of tangible fixed assets  owned b...  \n1        cost of equity settled share based payments  \n2                           amortisation of software  \n3                         auditor remuneration audit  \n4                operating lease payables  equipment  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>desc</th>\n      <th>label</th>\n      <th>desc_parsed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Depreciation of tangible fixed assets - owned ...</td>\n      <td>d_and_a</td>\n      <td>depreciation of tangible fixed assets  owned b...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cost of equity settled share based payments</td>\n      <td>adjustment</td>\n      <td>cost of equity settled share based payments</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Amortisation of software</td>\n      <td>d_and_a</td>\n      <td>amortisation of software</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Auditor's remuneration: Audit</td>\n      <td>other</td>\n      <td>auditor remuneration audit</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Operating lease payables - equipment</td>\n      <td>other</td>\n      <td>operating lease payables  equipment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rearrange dataframe\n\n'''list_columns = [\"desc\", \"label\", \"desc_parsed5\",]\ndata = data[list_columns]\ndata = data.rename(columns={'desc_parsed5': 'desc_parsed'})\n\ndata.head()'''","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"'list_columns = [\"desc\", \"label\", \"desc_parsed5\",]\\ndata = data[list_columns]\\ndata = data.rename(columns={\\'desc_parsed5\\': \\'desc_parsed\\'})\\n\\ndata.head()'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc = data['desc']\nlabel = data['label']\n\n# label encode the target variable \nencoder = preprocessing.LabelEncoder()\nlabel = encoder.fit_transform(label)\n\ntrain_x, test_x, train_y, test_y = model_selection.train_test_split(desc, label,test_size=0.20, random_state=10)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create count vectorizer feature \ncount_vect = CountVectorizer()\n#count_vect.fit(desc)\ntrain_count =  count_vect.fit_transform(train_x)\ntest_count =  count_vect.transform(test_x)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word level tf-idf\ntfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\ntfidf_vect.fit(desc)\ntrain_tfidf =  tfidf_vect.transform(train_x)\ntest_tfidf =  tfidf_vect.transform(test_x)\n\n# ngram level tf-idf \ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram.fit(desc)\ntrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\ntest_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)\n\n# characters level tf-idf\ntfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram_chars.fit(desc)\ntrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \ntest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x) ","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(classifier, feature_train, label, feature_test, model_name, is_neural_net=False):\n    # fit the training dataset on the classifier\n    classifier.fit(feature_train, label)\n    with open(model_name, 'wb') as picklefile:\n        pickle.dump(classifier,picklefile)\n    # predict the labels on validation dataset\n    predictions = classifier.predict(feature_test)\n    \n    if is_neural_net:\n        predictions = predictions.argmax(axis=-1)\n    \n    return metrics.accuracy_score(predictions, test_y)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NAIVE BAYES\n\n# Count Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), train_count, train_y, test_count, 'NaiveBayesCV')\nprint (\"NB, Count Vectors: \", accuracy)\n\n# Word Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf, train_y, test_tfidf, 'NaiveBayesTfidf')\nprint (\"NB, WordLevel TF-IDF: \", accuracy)\n\n# Ngram Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'NaiveBayesTfidfNgram')\nprint (\"NB, N-Gram Vectors: \", accuracy)\n\n# Character Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'NaiveBayesTfidfNgramChars')\n\nprint (\"NB, CharLevel Vectors: \", accuracy)","execution_count":57,"outputs":[{"output_type":"stream","text":"NB, Count Vectors:  0.9357142857142857\nNB, WordLevel TF-IDF:  0.95\nNB, N-Gram Vectors:  0.8357142857142857\nNB, CharLevel Vectors:  0.9642857142857143\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOGISTIC REGRESSION\n\n# Count Vectors\naccuracy = train_model(linear_model.LogisticRegression(), train_count, train_y, test_count, 'LogisticRegressionCV')\nprint (\"LR, Count Vectors: \", accuracy)\n\n# Word Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(), train_tfidf, train_y, test_tfidf, 'LogisticRegressionTfidf')\nprint (\"LR, WordLevel TF-IDF: \", accuracy)\n\n# Ngram Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'LogisticRegressionTfidfNgram')\nprint (\"LR, N-Gram Vectors: \", accuracy)\n\n# Character Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'LogisticRegressionTfidfNgramChars')\nprint (\"LR, CharLevel Vectors: \", accuracy)","execution_count":58,"outputs":[{"output_type":"stream","text":"LR, Count Vectors:  0.95\nLR, WordLevel TF-IDF:  0.9571428571428572\nLR, N-Gram Vectors:  0.7928571428571428\nLR, CharLevel Vectors:  0.9714285714285714\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RANDOM FOREST\n\n# Count Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(), train_count, train_y, test_count, 'RandomForestCV')\nprint (\"RF, Count Vectors: \", accuracy)\n\n# Word Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf, train_y, test_tfidf, 'RandomForestTfidf')\nprint (\"RF, WordLevel TF-IDF: \", accuracy)\n\n# Ngram Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'RandomForestTfidfNgram')\nprint (\"RF, Count Vectors: \", accuracy)\n\n# Character Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'RandomForestTfidfNgramChars')\nprint (\"RF, WordLevel TF-IDF: \", accuracy)","execution_count":59,"outputs":[{"output_type":"stream","text":"RF, Count Vectors:  0.9571428571428572\nRF, WordLevel TF-IDF:  0.9357142857142857\nRF, Count Vectors:  0.7714285714285715\nRF, WordLevel TF-IDF:  0.9428571428571428\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EXTREME GRADIENT BOOSTING\n\n# Count Vectors\naccuracy = train_model(xgboost.XGBClassifier(), train_count.tocsc(), train_y, test_count.tocsc(),'XGBoostCV')\nprint (\"Xgb, Count Vectors: \", accuracy)\n\n# Word Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), train_tfidf.tocsc(), train_y, test_tfidf.tocsc(),'XGBoostTfidf')\nprint (\"Xgb, WordLevel TF-IDF: \", accuracy)\n\n# Ngram Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), train_tfidf_ngram.tocsc(), train_y, test_tfidf_ngram.tocsc(),'XGBoostTfidfNgram')\nprint (\"Xgb, Ngram Vectors: \", accuracy)\n\n# Character Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), train_tfidf_ngram_chars.tocsc(), train_y, test_tfidf_ngram_chars.tocsc(),'XGBoostTfidfNgramChars')\nprint (\"Xgb, CharLevel Vectors: \", accuracy)\n\n","execution_count":60,"outputs":[{"output_type":"stream","text":"Xgb, Count Vectors:  0.9428571428571428\nXgb, WordLevel TF-IDF:  0.9142857142857143\nXgb, Ngram Vectors:  0.8214285714285714\nXgb, CharLevel Vectors:  0.9642857142857143\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/text-classification-2/LogisticRegressionCV', 'rb') as training_model:\n    LRCVModel = pickle.load(training_model)\nwith open('../input/text-classification-2/LogisticRegressionTfidf', 'rb') as training_model:\n    LRTfidfModel = pickle.load(training_model)\nwith open('../input/text-classification-2/LogisticRegressionTfidfNgramChars', 'rb') as training_model:\n    LRTfidfNgramCharsModel = pickle.load(training_model)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while(1):\n    text = input(\"Enter a text to categorize Otherwise press 'q' to exit:\")\n    if (text == 'q') or (text == 'Q'):\n        break\n    text = [cleanText(text)]\n    #text = []\n    #text.append(textCleaned)\n    text\n    text_cv = count_vect.transform(text)\n    text_tfidf = tfidf_vect.transform(text)\n    text_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(text)\n    pred1 = LRTfidfNgramCharsModel.predict(text_tfidf_ngram_chars)\n    pred2 = LRCVModel.predict(text_cv)\n    pred3 = LRTfidfModel.predict(text_tfidf)\n    print('\\n\\nCategory based on Character level ngrams using Logistic Regrssion - ', encoder.inverse_transform(pred1)[0])\n    print('Category based on count vector using Logistic Regrssion - ', encoder.inverse_transform(pred2)[0])\n    print('Category based on tfidf using Logistic Regrssion - ', encoder.inverse_transform(pred3)[0], '\\n\\n')","execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":"Enter a text to categorize Otherwise press 'q' to exit:Foreign exchange differences (crediting)\n\n\nCategory based on Character level ngrams using Logistic Regrssion -  adjustment\nCategory based on count vector using Logistic Regrssion -  adjustment\nCategory based on tfidf using Logistic Regrssion -  adjustment \n\n\nEnter a text to categorize Otherwise press 'q' to exit:exceptional administrative expenses - EBT settlement\n\n\nCategory based on Character level ngrams using Logistic Regrssion -  adjustment\nCategory based on count vector using Logistic Regrssion -  adjustment\nCategory based on tfidf using Logistic Regrssion -  adjustment \n\n\nEnter a text to categorize Otherwise press 'q' to exit:Depreciation of intangible fixed assets - owned by the group\n\n\nCategory based on Character level ngrams using Logistic Regrssion -  d_and_a\nCategory based on count vector using Logistic Regrssion -  d_and_a\nCategory based on tfidf using Logistic Regrssion -  d_and_a \n\n\nEnter a text to categorize Otherwise press 'q' to exit:Auditor's remuneration - Audit services\n\n\nCategory based on Character level ngrams using Logistic Regrssion -  other\nCategory based on count vector using Logistic Regrssion -  other\nCategory based on tfidf using Logistic Regrssion -  other \n\n\nEnter a text to categorize Otherwise press 'q' to exit:q\n"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}