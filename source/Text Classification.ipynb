{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost, numpy, textblob, string, pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Depreciation of tangible fixed assets - owned ...</td>\n",
       "      <td>d_and_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cost of equity settled share based payments</td>\n",
       "      <td>adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amortisation of software</td>\n",
       "      <td>d_and_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auditor's remuneration: Audit</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operating lease payables - equipment</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc       label\n",
       "0  Depreciation of tangible fixed assets - owned ...     d_and_a\n",
       "1        Cost of equity settled share based payments  adjustment\n",
       "2                           Amortisation of software     d_and_a\n",
       "3                      Auditor's remuneration: Audit       other\n",
       "4               Operating lease payables - equipment       other"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(\"../input/sample.csv\",names=['desc', 'label'], header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "def cleanText(text):\n",
    "    # Remove unwanted /r, /n, spaces and quotes\n",
    "    textParsed = text.replace(\"\\r\", \" \")\n",
    "    textParsed = textParsed.replace(\"\\n\", \" \")\n",
    "    textParsed = textParsed.replace(\"    \", \" \")\n",
    "    textParsed = textParsed.replace('\"\"', '')\n",
    "\n",
    "    # Convert text to lower case\n",
    "    textParsed = textParsed.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    punctuation_signs = list(\"?:!.,);-/(\")\n",
    "    for punct_sign in punctuation_signs:\n",
    "        textParsed = textParsed.replace(punct_sign, '')\n",
    "\n",
    "    # Remove's\n",
    "    textParsed = textParsed.replace(\"'s\", \"\")\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        textParsed = textParsed.replace(regex_stopword, '')\n",
    "    return textParsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "      <th>desc_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Depreciation of tangible fixed assets - owned ...</td>\n",
       "      <td>d_and_a</td>\n",
       "      <td>depreciation of tangible fixed assets  owned b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cost of equity settled share based payments</td>\n",
       "      <td>adjustment</td>\n",
       "      <td>cost of equity settled share based payments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amortisation of software</td>\n",
       "      <td>d_and_a</td>\n",
       "      <td>amortisation of software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auditor's remuneration: Audit</td>\n",
       "      <td>other</td>\n",
       "      <td>auditor remuneration audit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operating lease payables - equipment</td>\n",
       "      <td>other</td>\n",
       "      <td>operating lease payables  equipment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc       label  \\\n",
       "0  Depreciation of tangible fixed assets - owned ...     d_and_a   \n",
       "1        Cost of equity settled share based payments  adjustment   \n",
       "2                           Amortisation of software     d_and_a   \n",
       "3                      Auditor's remuneration: Audit       other   \n",
       "4               Operating lease payables - equipment       other   \n",
       "\n",
       "                                         desc_parsed  \n",
       "0  depreciation of tangible fixed assets  owned b...  \n",
       "1        cost of equity settled share based payments  \n",
       "2                           amortisation of software  \n",
       "3                         auditor remuneration audit  \n",
       "4                operating lease payables  equipment  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descParsed = []\n",
    "for text in data['desc']:\n",
    "    textparsed = cleanText(text)\n",
    "    descParsed.append(textparsed)\n",
    "data['desc_parsed'] = descParsed\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = data['desc']\n",
    "label = data['label']\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "label = encoder.fit_transform(label)\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(desc, label,test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create count vectorizer feature \n",
    "count_vect = CountVectorizer()\n",
    "#count_vect.fit(desc)\n",
    "train_count =  count_vect.fit_transform(train_x)\n",
    "test_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(desc)\n",
    "train_tfidf =  tfidf_vect.transform(train_x)\n",
    "test_tfidf =  tfidf_vect.transform(test_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(desc)\n",
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(desc)\n",
    "train_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "test_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_train, label, feature_test, model_name, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_train, label)\n",
    "    with open(model_name, 'wb') as picklefile:\n",
    "        pickle.dump(classifier,picklefile)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_test)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.9357142857142857\n",
      "NB, WordLevel TF-IDF:  0.95\n",
      "NB, N-Gram Vectors:  0.8357142857142857\n",
      "NB, CharLevel Vectors:  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "# Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_count, train_y, test_count, 'NaiveBayesCV')\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf, train_y, test_tfidf, 'NaiveBayesTfidf')\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'NaiveBayesTfidfNgram')\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'NaiveBayesTfidfNgramChars')\n",
    "\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.95\n",
      "LR, WordLevel TF-IDF:  0.9571428571428572\n",
      "LR, N-Gram Vectors:  0.7928571428571428\n",
      "LR, CharLevel Vectors:  0.9714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_count, train_y, test_count, 'LogisticRegressionCV')\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_tfidf, train_y, test_tfidf, 'LogisticRegressionTfidf')\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'LogisticRegressionTfidfNgram')\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'LogisticRegressionTfidfNgramChars')\n",
    "print (\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.9571428571428572\n",
      "RF, WordLevel TF-IDF:  0.9357142857142857\n",
      "RF, Count Vectors:  0.7714285714285715\n",
      "RF, WordLevel TF-IDF:  0.9428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "# Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), train_count, train_y, test_count, 'RandomForestCV')\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf, train_y, test_tfidf, 'RandomForestTfidf')\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf_ngram, train_y, test_tfidf_ngram, 'RandomForestTfidfNgram')\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# Character Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), train_tfidf_ngram_chars, train_y, test_tfidf_ngram_chars, 'RandomForestTfidfNgramChars')\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.9428571428571428\n",
      "Xgb, WordLevel TF-IDF:  0.9142857142857143\n",
      "Xgb, Ngram Vectors:  0.8214285714285714\n",
      "Xgb, CharLevel Vectors:  0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "#EXTREME GRADIENT BOOSTING\n",
    "\n",
    "# Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), train_count.tocsc(), train_y, test_count.tocsc(),'XGBoostCV')\n",
    "print (\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), train_tfidf.tocsc(), train_y, test_tfidf.tocsc(),'XGBoostTfidf')\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), train_tfidf_ngram.tocsc(), train_y, test_tfidf_ngram.tocsc(),'XGBoostTfidfNgram')\n",
    "print (\"Xgb, Ngram Vectors: \", accuracy)\n",
    "\n",
    "# Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), train_tfidf_ngram_chars.tocsc(), train_y, test_tfidf_ngram_chars.tocsc(),'XGBoostTfidfNgramChars')\n",
    "print (\"Xgb, CharLevel Vectors: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/LogisticRegressionCV', 'rb') as training_model:\n",
    "    LRCVModel = pickle.load(training_model)\n",
    "with open('../input/LogisticRegressionTfidf', 'rb') as training_model:\n",
    "    LRTfidfModel = pickle.load(training_model)\n",
    "with open('../input/LogisticRegressionTfidfNgramChars', 'rb') as training_model:\n",
    "    LRTfidfNgramCharsModel = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text to categorize Otherwise press 'q' to exit:Foreign exchange differences (crediting)\n",
      "\n",
      "\n",
      "Category based on Character level ngrams using Logistic Regrssion -  adjustment\n",
      "Category based on count vector using Logistic Regrssion -  adjustment\n",
      "Category based on tfidf using Logistic Regrssion -  adjustment \n",
      "\n",
      "\n",
      "Enter a text to categorize Otherwise press 'q' to exit:exceptional administrative expenses - EBT settlement\n",
      "\n",
      "\n",
      "Category based on Character level ngrams using Logistic Regrssion -  adjustment\n",
      "Category based on count vector using Logistic Regrssion -  adjustment\n",
      "Category based on tfidf using Logistic Regrssion -  adjustment \n",
      "\n",
      "\n",
      "Enter a text to categorize Otherwise press 'q' to exit:Depreciation of intangible fixed assets - owned by the group\n",
      "\n",
      "\n",
      "Category based on Character level ngrams using Logistic Regrssion -  d_and_a\n",
      "Category based on count vector using Logistic Regrssion -  d_and_a\n",
      "Category based on tfidf using Logistic Regrssion -  d_and_a \n",
      "\n",
      "\n",
      "Enter a text to categorize Otherwise press 'q' to exit:Auditor's remuneration - Audit services\n",
      "\n",
      "\n",
      "Category based on Character level ngrams using Logistic Regrssion -  other\n",
      "Category based on count vector using Logistic Regrssion -  other\n",
      "Category based on tfidf using Logistic Regrssion -  other \n",
      "\n",
      "\n",
      "Enter a text to categorize Otherwise press 'q' to exit:q\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    text = input(\"Enter a text to categorize Otherwise press 'q' to exit:\")\n",
    "    if (text == 'q') or (text == 'Q'):\n",
    "        break\n",
    "    text = [cleanText(text)]\n",
    "    #text = []\n",
    "    #text.append(textCleaned)\n",
    "    text\n",
    "    text_cv = count_vect.transform(text)\n",
    "    text_tfidf = tfidf_vect.transform(text)\n",
    "    text_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(text)\n",
    "    pred1 = LRTfidfNgramCharsModel.predict(text_tfidf_ngram_chars)\n",
    "    pred2 = LRCVModel.predict(text_cv)\n",
    "    pred3 = LRTfidfModel.predict(text_tfidf)\n",
    "    print('\\n\\nCategory based on Character level ngrams using Logistic Regrssion - ', encoder.inverse_transform(pred1)[0])\n",
    "    print('Category based on count vector using Logistic Regrssion - ', encoder.inverse_transform(pred2)[0])\n",
    "    print('Category based on tfidf using Logistic Regrssion - ', encoder.inverse_transform(pred3)[0], '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
